{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504405fd-6139-49ca-b7ad-97e7073758f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b384861e-0bc8-4b58-833b-9298abb4ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(data1, data2, data3, data4, common_key, target_column):\n",
    "    \"\"\"Charge, fusionne et nettoie les fichiers CSV.\"\"\"\n",
    "    caract = pd.read_csv(data1, sep=\";\", low_memory=False)\n",
    "    lieux = pd.read_csv(data2, sep=\";\", low_memory=False)\n",
    "    usagers = pd.read_csv(data3, sep=\";\", low_memory=False)\n",
    "    vehicules = pd.read_csv(data4, sep=\";\", low_memory=False)\n",
    "    \n",
    "    merged_df = caract.merge(lieux, on=common_key, how=\"inner\") \\\n",
    "                      .merge(usagers, on=common_key, how=\"inner\") \\\n",
    "                      .merge(vehicules, on=common_key, how=\"inner\")\n",
    "    \n",
    "    print(f\"Colonnes disponibles après fusion : {merged_df.columns.tolist()}\")\n",
    "\n",
    "    merged_df = merged_df.dropna(axis=1, how='all')\n",
    "    merged_df = merged_df.loc[:, merged_df.nunique() > 1]\n",
    "    \n",
    "    y = merged_df[target_column]\n",
    "    X = merged_df.drop(columns=[target_column, common_key])\n",
    "    return X, y\n",
    "\n",
    "def correlation_matrix(X, y, threshold=0.1):\n",
    "    \"\"\"Filtre les colonnes numériques basées sur leur corrélation avec la cible.\"\"\"\n",
    "    correlations = {}\n",
    "    for col in X.select_dtypes(include=[np.number]).columns:\n",
    "        corr = np.corrcoef(X[col], y)[0, 1]\n",
    "        correlations[col] = corr\n",
    "    selected = [col for col, corr in correlations.items() if abs(corr) > threshold]\n",
    "    print(f\"Colonnes numériques retenues (corrélation > {threshold}): {selected}\")\n",
    "    return selected\n",
    "\n",
    "def categorical_analysis(X, y, threshold=0.2):\n",
    "    \"\"\"Filtre les colonnes catégorielles en se basant sur la variance des moyennes.\"\"\"\n",
    "    X_with_target = X.copy()\n",
    "    X_with_target['target'] = y\n",
    "\n",
    "    selected = []\n",
    "    for col in X.select_dtypes(include='object').columns:\n",
    "        means = X_with_target.groupby(col)['target'].mean()\n",
    "        if means.var() > threshold:\n",
    "            selected.append(col)\n",
    "    print(f\"Colonnes catégorielles retenues (variance > {threshold}): {selected}\")\n",
    "    return selected\n",
    "\n",
    "def low_variance_filter(X, threshold=0.01):\n",
    "    \"\"\"Filtre les colonnes numériques avec une faible variance.\"\"\"\n",
    "    X_numeric = X.select_dtypes(include=[np.number])\n",
    "    variances = X_numeric.var()\n",
    "    selected = variances[variances > threshold].index.tolist()\n",
    "    print(f\"Colonnes numériques retenues (variance > {threshold}): {selected}\")\n",
    "    return selected\n",
    "\n",
    "\n",
    "def auto_handle_nan(df, nan_threshold_delete=0.5, nan_threshold_impute=0.1):\n",
    "    \"\"\"\n",
    "    Traite automatiquement les valeurs NaN dans un dataset.\n",
    "    - Supprime les colonnes avec trop de NaN.\n",
    "    - Impute (remplace) les NaN avec des stratégies adaptées :\n",
    "      - Moyenne pour colonnes numériques.\n",
    "      - Mode ou \"Inconnu\" pour colonnes catégorielles.\n",
    "    \"\"\"\n",
    "    print(\"Analyse des NaN dans le dataset...\\n\")\n",
    "    \n",
    "    nan_percent = df.isnull().mean()\n",
    "    print(\"Pourcentage de valeurs manquantes par colonne :\")\n",
    "    print(nan_percent)\n",
    "    \n",
    "    cols_to_delete = nan_percent[nan_percent > nan_threshold_delete].index\n",
    "    print(f\"\\nColonnes supprimées (trop de NaN > {nan_threshold_delete*100}%): {list(cols_to_delete)}\")\n",
    "    df = df.drop(columns=cols_to_delete)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        missing = df[col].isnull().sum()\n",
    "        if missing > 0:\n",
    "            if df[col].dtype == 'object':\n",
    "                if nan_percent[col] > nan_threshold_impute:\n",
    "                    print(f\"Colonne '{col}' : Imputation avec 'Manquant' (catégorielle)\")\n",
    "                    df[col] = df[col].fillna(\"Manquant\")\n",
    "                else:\n",
    "                    print(f\"Colonne '{col}' : Imputation avec la valeur la plus fréquente (mode)\")\n",
    "                    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "            else:\n",
    "                if nan_percent[col] > nan_threshold_impute:\n",
    "                    print(f\"Colonne '{col}' : Imputation avec la médiane (numérique)\")\n",
    "                    df[col] = df[col].fillna(df[col].median())\n",
    "                else:\n",
    "                    print(f\"Colonne '{col}' : Imputation avec la moyenne (numérique)\")\n",
    "                    df[col] = df[col].fillna(df[col].mean())\n",
    "    \n",
    "    print(\"\\nTraitement des NaN terminé.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4696f6e-5924-4dcb-9cd1-75e13bc64fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data1, data2, data3, data4, common_key, target_column):\n",
    "    print(\"Chargement et fusion des données...\")\n",
    "    X, y = load_and_process_data(data1, data2, data3, data4, common_key, target_column)\n",
    "\n",
    "    print(\"\\nSuppression des doublons...\")\n",
    "    print(\"Nombre de doublons avant suppression :\", X.duplicated().sum())\n",
    "    X = X.drop_duplicates()\n",
    "    print(\"Nombre de doublons après suppression :\", X.duplicated().sum())\n",
    "\n",
    "    print(\"\\nTraitement des valeurs NaN...\")\n",
    "    X = auto_handle_nan(X)\n",
    "\n",
    "    print(\"\\nSélection des colonnes numériques importantes...\")\n",
    "    numeric_cols_corr = correlation_matrix(X, y, threshold=0.1)\n",
    "    numeric_cols_var = low_variance_filter(X, threshold=0.1)\n",
    "\n",
    "    print(\"\\nSélection des colonnes catégorielles importantes...\")\n",
    "    categorical_cols = categorical_analysis(X, y, threshold=2)\n",
    "\n",
    "    selected_columns = list(set(numeric_cols_var + categorical_cols))\n",
    "    print(f\"\\nColonnes finales sélectionnées : {selected_columns}\")\n",
    "\n",
    "    X_filtered = X[selected_columns]\n",
    "    # final_data = pd.concat([X_filtered, y], axis=1)\n",
    "\n",
    "    print(\"\\nRésumé des colonnes importantes pour la prédiction :\")\n",
    "    print(f\"Nombre de colonnes finales : {len(X_filtered.columns)}\")\n",
    "    print(X_filtered.head())\n",
    "    return X_filtered, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885e17c8-41d2-46ae-9fd9-e4595dd5be41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du script...\n",
      "Chargement et fusion des données...\n",
      "Colonnes disponibles après fusion : ['Num_Acc', 'jour', 'mois', 'an', 'hrmn', 'lum', 'dep', 'com', 'agg', 'int', 'atm', 'col', 'adr', 'lat', 'long', 'catr', 'voie', 'v1', 'v2', 'circ', 'nbv', 'vosp', 'prof', 'pr', 'pr1', 'plan', 'lartpc', 'larrout', 'surf', 'infra', 'situ', 'vma', 'id_usager', 'id_vehicule_x', 'num_veh_x', 'place', 'catu', 'grav', 'sexe', 'an_nais', 'trajet', 'secu1', 'secu2', 'secu3', 'locp', 'actp', 'etatp', 'id_vehicule_y', 'num_veh_y', 'senc', 'catv', 'obs', 'obsm', 'choc', 'manv', 'motor', 'occutc']\n",
      "\n",
      "Suppression des doublons...\n",
      "Nombre de doublons avant suppression : 0\n",
      "Nombre de doublons après suppression : 0\n",
      "\n",
      "Traitement des valeurs NaN...\n",
      "Analyse des NaN dans le dataset...\n",
      "\n",
      "Pourcentage de valeurs manquantes par colonne :\n",
      "jour             0.000000\n",
      "mois             0.000000\n",
      "hrmn             0.000000\n",
      "lum              0.000000\n",
      "dep              0.000000\n",
      "com              0.000000\n",
      "agg              0.000000\n",
      "int              0.000000\n",
      "atm              0.000000\n",
      "col              0.000000\n",
      "adr              0.025318\n",
      "lat              0.000000\n",
      "long             0.000000\n",
      "catr             0.000000\n",
      "voie             0.163079\n",
      "v1               0.000000\n",
      "v2               0.917053\n",
      "circ             0.000000\n",
      "nbv              0.000000\n",
      "vosp             0.000000\n",
      "prof             0.000000\n",
      "pr               0.000000\n",
      "pr1              0.000000\n",
      "plan             0.000000\n",
      "lartpc           0.999483\n",
      "larrout          0.000000\n",
      "surf             0.000000\n",
      "infra            0.000000\n",
      "situ             0.000000\n",
      "vma              0.000000\n",
      "id_usager        0.000000\n",
      "id_vehicule_x    0.000000\n",
      "num_veh_x        0.000000\n",
      "place            0.000000\n",
      "catu             0.000000\n",
      "sexe             0.000000\n",
      "an_nais          0.020547\n",
      "trajet           0.000000\n",
      "secu1            0.000000\n",
      "secu2            0.000000\n",
      "secu3            0.000000\n",
      "locp             0.000000\n",
      "actp             0.000000\n",
      "etatp            0.000000\n",
      "id_vehicule_y    0.000000\n",
      "num_veh_y        0.000000\n",
      "senc             0.000000\n",
      "catv             0.000000\n",
      "obs              0.000000\n",
      "obsm             0.000000\n",
      "choc             0.000000\n",
      "manv             0.000000\n",
      "motor            0.000000\n",
      "occutc           0.987176\n",
      "dtype: float64\n",
      "\n",
      "Colonnes supprimées (trop de NaN > 50.0%): ['v2', 'lartpc', 'occutc']\n",
      "Colonne 'adr' : Imputation avec la valeur la plus fréquente (mode)\n",
      "Colonne 'voie' : Imputation avec 'Manquant' (catégorielle)\n",
      "Colonne 'an_nais' : Imputation avec la moyenne (numérique)\n",
      "\n",
      "Traitement des NaN terminé.\n",
      "\n",
      "Sélection des colonnes numériques importantes...\n",
      "Colonnes numériques retenues (corrélation > 0.1): ['place', 'catu', 'sexe', 'secu1', 'secu2', 'locp', 'etatp']\n",
      "Colonnes numériques retenues (variance > 0.1): ['jour', 'mois', 'lum', 'agg', 'int', 'atm', 'col', 'catr', 'v1', 'circ', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ', 'vma', 'place', 'catu', 'sexe', 'an_nais', 'trajet', 'secu1', 'secu2', 'secu3', 'locp', 'etatp', 'senc', 'catv', 'obs', 'obsm', 'choc', 'manv', 'motor']\n",
      "\n",
      "Sélection des colonnes catégorielles importantes...\n",
      "Colonnes catégorielles retenues (variance > 2): []\n",
      "\n",
      "Colonnes finales sélectionnées : ['sexe', 'etatp', 'plan', 'manv', 'infra', 'catr', 'secu2', 'choc', 'catu', 'prof', 'atm', 'lum', 'agg', 'vma', 'trajet', 'an_nais', 'int', 'surf', 'secu3', 'v1', 'circ', 'col', 'jour', 'mois', 'motor', 'locp', 'secu1', 'vosp', 'place', 'obs', 'catv', 'senc', 'obsm', 'situ']\n",
      "\n",
      "Résumé des colonnes importantes pour la prédiction :\n",
      "Nombre de colonnes finales : 34\n",
      "   sexe  etatp  plan  manv  infra  catr  secu2  choc  catu  prof  ...  motor  \\\n",
      "0     1     -1     1     1      0     4      0     5     1     1  ...      1   \n",
      "1     1     -1     1     1      0     4      0     5     1     1  ...      1   \n",
      "2     2     -1     1     1      0     3      0     1     1     1  ...      1   \n",
      "3     1      1     1     1      0     3     -1     1     3     1  ...      1   \n",
      "4     1     -1     1    16      5     3      6     1     1     1  ...      1   \n",
      "\n",
      "   locp  secu1  vosp  place  obs  catv  senc  obsm  situ  \n",
      "0    -1      2     0      1    0    30     1     0     1  \n",
      "1    -1      2     0      1    0    30     1     0     1  \n",
      "2    -1      1     2      1    0     7     2     1     1  \n",
      "3     2      0     2     10    0     7     2     1     1  \n",
      "4     0      2     0      1    0     2     1     2     1  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Lancement du pipeline AutoML...\n",
      "Division des données en ensembles d'entraînement et de validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:01:14,172] A new study created in memory with name: no-name-c55be97a-78bc-418a-ae02-24bc60e468b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du modèle : NeuralNetwork\n",
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/456\n",
      "Époque 50/456\n",
      "Époque 100/456\n",
      "Époque 150/456\n",
      "Époque 200/456\n",
      "Époque 250/456\n",
      "Époque 300/456\n",
      "Époque 350/456\n",
      "Époque 400/456\n",
      "Époque 450/456\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:06:21,853] Trial 0 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.02032657664346339, 'hidden_size': 50, 'epochs': 456}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/291\n",
      "Époque 50/291\n",
      "Époque 100/291\n",
      "Époque 150/291\n",
      "Époque 200/291\n",
      "Époque 250/291\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:09:05,352] Trial 1 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.0009787182993110618, 'hidden_size': 31, 'epochs': 291}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/449\n",
      "Époque 50/449\n",
      "Époque 100/449\n",
      "Époque 150/449\n",
      "Époque 200/449\n",
      "Époque 250/449\n",
      "Époque 300/449\n",
      "Époque 350/449\n",
      "Époque 400/449\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:12:45,397] Trial 2 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.06704511957747732, 'hidden_size': 16, 'epochs': 449}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/122\n",
      "Époque 50/122\n",
      "Époque 100/122\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:13:45,160] Trial 3 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.0004525760872971236, 'hidden_size': 6, 'epochs': 122}. Best is trial 0 with value: 0.4568847080120901.\n",
      "/var/folders/6_/z1bmyj3n2tn0lxd9mp0y82m40000gn/T/ipykernel_27881/4095821676.py:19: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/430\n",
      "Époque 50/430\n",
      "Époque 100/430\n",
      "Époque 150/430\n",
      "Époque 200/430\n",
      "Époque 250/430\n",
      "Époque 300/430\n",
      "Époque 350/430\n",
      "Époque 400/430\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:17:45,446] Trial 4 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.004299220206195436, 'hidden_size': 25, 'epochs': 430}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/278\n",
      "Époque 50/278\n",
      "Époque 100/278\n",
      "Époque 150/278\n",
      "Époque 200/278\n",
      "Époque 250/278\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:20:11,657] Trial 5 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.005630730647364498, 'hidden_size': 19, 'epochs': 278}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/170\n",
      "Époque 50/170\n",
      "Époque 100/170\n",
      "Époque 150/170\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:21:49,369] Trial 6 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.012517468985295701, 'hidden_size': 30, 'epochs': 170}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/451\n",
      "Époque 50/451\n",
      "Époque 100/451\n",
      "Époque 150/451\n",
      "Époque 200/451\n",
      "Époque 250/451\n",
      "Époque 300/451\n",
      "Époque 350/451\n",
      "Époque 400/451\n",
      "Époque 450/451\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:26:11,304] Trial 7 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.002259944406555066, 'hidden_size': 35, 'epochs': 451}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/254\n",
      "Époque 50/254\n",
      "Époque 100/254\n",
      "Époque 150/254\n",
      "Époque 200/254\n",
      "Époque 250/254\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:28:29,043] Trial 8 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.04024841068535831, 'hidden_size': 11, 'epochs': 254}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour NeuralNetwork...\n",
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/158\n",
      "Époque 50/158\n",
      "Époque 100/158\n",
      "Époque 150/158\n",
      "Prédictions avec le NeuralNetwork...\n",
      "Calcul de la précision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:29:48,398] Trial 9 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.009490651035605386, 'hidden_size': 14, 'epochs': 158}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du NeuralNetwork...\n",
      "Début de l'entraînement du NeuralNetwork...\n",
      "Époque 0/456\n",
      "Époque 50/456\n",
      "Époque 100/456\n",
      "Époque 150/456\n",
      "Époque 200/456\n",
      "Époque 250/456\n",
      "Époque 300/456\n",
      "Époque 350/456\n",
      "Époque 400/456\n",
      "Époque 450/456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:34:30,494] A new study created in memory with name: no-name-ab55ab01-846d-47a1-8c5f-47cbc6e45b50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du modèle : LogisticRegression\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/202\n",
      "Époque 50/202\n",
      "Époque 100/202\n",
      "Époque 150/202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:34:34,241] Trial 0 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.001849605380466895, 'epochs': 202}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 200/202\n",
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/313\n",
      "Époque 50/313\n",
      "Époque 100/313\n",
      "Époque 150/313\n",
      "Époque 200/313\n",
      "Époque 250/313\n",
      "Époque 300/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:34:39,625] Trial 1 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.03594057062774646, 'epochs': 313}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/323\n",
      "Époque 50/323\n",
      "Époque 100/323\n",
      "Époque 150/323\n",
      "Époque 200/323\n",
      "Époque 250/323\n",
      "Époque 300/323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:34:45,372] Trial 2 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.037964462713207615, 'epochs': 323}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/193\n",
      "Époque 50/193\n",
      "Époque 100/193\n",
      "Époque 150/193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:34:49,267] Trial 3 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.00014162746582859043, 'epochs': 193}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/272\n",
      "Époque 50/272\n",
      "Époque 100/272\n",
      "Époque 150/272\n",
      "Époque 200/272\n",
      "Époque 250/272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:34:54,806] Trial 4 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.00015417410422149822, 'epochs': 272}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/323\n",
      "Époque 50/323\n",
      "Époque 100/323\n",
      "Époque 150/323\n",
      "Époque 200/323\n",
      "Époque 250/323\n",
      "Époque 300/323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:35:01,133] Trial 5 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.00015489941416403207, 'epochs': 323}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/473\n",
      "Époque 50/473\n",
      "Époque 100/473\n",
      "Époque 150/473\n",
      "Époque 200/473\n",
      "Époque 250/473\n",
      "Époque 300/473\n",
      "Époque 350/473\n",
      "Époque 400/473\n",
      "Époque 450/473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:35:10,350] Trial 6 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.01339345643890415, 'epochs': 473}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/285\n",
      "Époque 50/285\n",
      "Époque 100/285\n",
      "Époque 150/285\n",
      "Époque 200/285\n",
      "Époque 250/285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:35:16,066] Trial 7 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.016436339970281114, 'epochs': 285}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/252\n",
      "Époque 50/252\n",
      "Époque 100/252\n",
      "Époque 150/252\n",
      "Époque 200/252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:35:20,946] Trial 8 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.0033279683496246653, 'epochs': 252}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 250/252\n",
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Optimisation des hyperparamètres pour LogisticRegression...\n",
      "Initialisation de la LogisticRegression...\n",
      "Début de l'entraînement de la LogisticRegression...\n",
      "Époque 0/221\n",
      "Époque 50/221\n",
      "Époque 100/221\n",
      "Époque 150/221\n",
      "Époque 200/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 12:35:25,452] Trial 9 finished with value: 0.4568847080120901 and parameters: {'learning_rate': 0.007054699125015014, 'epochs': 221}. Best is trial 0 with value: 0.4568847080120901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec la LogisticRegression...\n",
      "Calcul de la précision...\n",
      "Pipeline AutoML terminé.\n",
      "Meilleur modèle : NeuralNetwork\n",
      "Meilleurs hyperparamètres : {'learning_rate': 0.02032657664346339, 'hidden_size': 50, 'epochs': 456}\n",
      "Meilleure précision : 0.4568847080120901\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01, epochs=500):\n",
    "        print(\"Initialisation du NeuralNetwork...\")\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) * 0.1\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size) * 0.1\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "\n",
    "    def fit(self, X, y, batch_size=32):\n",
    "        print(\"Début de l'entraînement du NeuralNetwork...\")\n",
    "        y = y.reshape(-1, self.output_size)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch % 50 == 0:\n",
    "                print(f\"Époque {epoch}/{self.epochs}\")\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                X_batch = X[i:i + batch_size]\n",
    "                y_batch = y[i:i + batch_size]\n",
    "\n",
    "                hidden_layer_activation = np.dot(X_batch, self.weights_input_hidden) + self.bias_hidden\n",
    "                hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
    "                final_layer_activation = np.dot(hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "                output = self.sigmoid(final_layer_activation)\n",
    "\n",
    "                error = y_batch - output\n",
    "                d_output = error * self.sigmoid_derivative(output)\n",
    "\n",
    "                d_hidden_layer = np.dot(d_output, self.weights_hidden_output.T) * self.sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "                self.weights_hidden_output += np.dot(hidden_layer_output.T, d_output) * self.learning_rate\n",
    "                self.bias_output += np.sum(d_output, axis=0, keepdims=True) * self.learning_rate\n",
    "                self.weights_input_hidden += np.dot(X_batch.T, d_hidden_layer) * self.learning_rate\n",
    "                self.bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Prédictions avec le NeuralNetwork...\")\n",
    "        hidden_layer_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
    "        final_layer_activation = np.dot(hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "        output = self.sigmoid(final_layer_activation)\n",
    "        return np.round(output)\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=500):\n",
    "        print(\"Initialisation de la LogisticRegression...\")\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(\"Début de l'entraînement de la LogisticRegression...\")\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "        m = len(y)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch % 50 == 0:\n",
    "                print(f\"Époque {epoch}/{self.epochs}\")\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = 1 / (1 + np.exp(-linear_model))\n",
    "\n",
    "            dw = (1 / m) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / m) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Prédictions avec la LogisticRegression...\")\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        predictions = 1 / (1 + np.exp(-linear_model))\n",
    "        return np.round(predictions)\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    print(\"Division des données en ensembles d'entraînement et de validation...\")\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split_idx = int(X.shape[0] * (1 - test_size))\n",
    "    train_indices = indices[:split_idx]\n",
    "    test_indices = indices[split_idx:]\n",
    "\n",
    "    X = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "    y = y.to_numpy() if isinstance(y, pd.Series) else y\n",
    "\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    print(\"Calcul de la précision...\")\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def optimize_model(trial, model_name, X_train, y_train, X_val, y_val):\n",
    "    print(f\"Optimisation des hyperparamètres pour {model_name}...\")\n",
    "    if model_name == \"NeuralNetwork\":\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 5, 50)\n",
    "        epochs = trial.suggest_int(\"epochs\", 100, 500)\n",
    "\n",
    "        model = NeuralNetwork(input_size=X_train.shape[1], hidden_size=hidden_size, output_size=1,\n",
    "                              learning_rate=learning_rate, epochs=epochs)\n",
    "    elif model_name == \"LogisticRegression\":\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "        epochs = trial.suggest_int(\"epochs\", 100, 500)\n",
    "\n",
    "        model = LogisticRegression(learning_rate=learning_rate, epochs=epochs)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    return accuracy_score(y_val, predictions)\n",
    "\n",
    "def auto_ml(X, y, models):\n",
    "    print(\"Lancement du pipeline AutoML...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    best_model_name = None\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "    final_model = None\n",
    "\n",
    "    for model_name in models:\n",
    "        print(f\"Évaluation du modèle : {model_name}\")\n",
    "        def objective(trial):\n",
    "            return optimize_model(trial, model_name, X_train, y_train, X_val, y_val)\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        if study.best_value > best_score:\n",
    "            best_model_name = model_name\n",
    "            best_params = study.best_params\n",
    "            best_score = study.best_value\n",
    "\n",
    "            if model_name == \"NeuralNetwork\":\n",
    "                final_model = NeuralNetwork(\n",
    "                    input_size=X_train.shape[1],\n",
    "                    hidden_size=best_params[\"hidden_size\"],\n",
    "                    output_size=1,\n",
    "                    learning_rate=best_params[\"learning_rate\"],\n",
    "                    epochs=best_params[\"epochs\"]\n",
    "                )\n",
    "            elif model_name == \"LogisticRegression\":\n",
    "                final_model = LogisticRegression(\n",
    "                    learning_rate=best_params[\"learning_rate\"],\n",
    "                    epochs=best_params[\"epochs\"]\n",
    "                )\n",
    "            final_model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Pipeline AutoML terminé.\")\n",
    "    return final_model, best_model_name, best_params, best_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Début du script...\")\n",
    "    X, y = preprocess_data(\"data/caract-2023.csv\", \"data/lieux-2023.csv\", \"data/usagers-2023.csv\", \"data/vehicules-2023.csv\", \"Num_Acc\", \"grav\")\n",
    "\n",
    "    models = [\"NeuralNetwork\", \"LogisticRegression\"]\n",
    "\n",
    "    final_model, best_model_name, best_params, best_score = auto_ml(X, y, models)\n",
    "\n",
    "    print(\"Meilleur modèle :\", best_model_name)\n",
    "    print(\"Meilleurs hyperparamètres :\", best_params)\n",
    "    print(\"Meilleure précision :\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a165037-d5cd-4232-94f4-5a2f7685023f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
